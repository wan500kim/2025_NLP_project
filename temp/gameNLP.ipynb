{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa01f5a3-8349-45f5-b864-d25a217f5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "MAX_SAMPLES = 10000\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "111e14d2-e78b-46de-b699-c381c8d529a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_file = Path(\"dataset/TL/용례_게임tl.json\")\n",
    "val_input_file = Path(\"dataset/VL/용례_게임vl.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5894c96e-1129-4a42-8844-7ad13f9c8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training examples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MAX_SAMPLES \u001b[38;5;129;01mand\u001b[39;00m count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m MAX_SAMPLES:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m char \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m char:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m    325\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_processed_data = []\n",
    "labels = set(['O'])\n",
    "\n",
    "with open(train_input_file, 'r', encoding='utf-8') as f:\n",
    "    f.read(1)\n",
    "    \n",
    "    buffer = \"\"\n",
    "    bracket_count = 0\n",
    "    in_string = False\n",
    "    escape = False\n",
    "    count = 0\n",
    "    \n",
    "    pbar = tqdm(desc=\"Processing training examples\")\n",
    "    \n",
    "    while True:\n",
    "        if MAX_SAMPLES and count >= MAX_SAMPLES:\n",
    "            break\n",
    "            \n",
    "        char = f.read(1)\n",
    "        if not char:\n",
    "            break\n",
    "        \n",
    "        buffer += char\n",
    "        \n",
    "        if char == '\"' and not escape:\n",
    "            in_string = not in_string\n",
    "        \n",
    "        escape = (char == '\\\\' and not escape)\n",
    "        \n",
    "        if not in_string:\n",
    "            if char == '{':\n",
    "                bracket_count += 1\n",
    "            elif char == '}':\n",
    "                bracket_count -= 1\n",
    "                \n",
    "                if bracket_count == 0:\n",
    "                    try:\n",
    "                        example = json.loads(buffer.strip().rstrip(','))\n",
    "                        count += 1\n",
    "                        pbar.update(1)\n",
    "                        \n",
    "                        sentence = example.get('sentence', '')\n",
    "                        tokens = example.get('tokens', [])\n",
    "                        \n",
    "                        if sentence and tokens:\n",
    "                            char_tags = ['O'] * len(sentence)\n",
    "                            \n",
    "                            for token in tokens:\n",
    "                                start = token['start']\n",
    "                                length = token['length']\n",
    "                                facet = token.get('facet', 'TERM')\n",
    "                                \n",
    "                                if start < len(sentence):\n",
    "                                    char_tags[start] = f'B-{facet}'\n",
    "                                \n",
    "                                for i in range(start + 1, start + length):\n",
    "                                    if i < len(sentence):\n",
    "                                        char_tags[i] = f'I-{facet}'\n",
    "                            \n",
    "                            chars = list(sentence)\n",
    "                            tags = char_tags\n",
    "                            labels.update(tags)\n",
    "                            \n",
    "                            train_processed_data.append({\n",
    "                                'id': example.get('id'),\n",
    "                                'sentence': sentence,\n",
    "                                'chars': chars,\n",
    "                                'tags': tags,\n",
    "                                'tokens': tokens\n",
    "                            })\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                    buffer = \"\"\n",
    "    \n",
    "    pbar.close()\n",
    "\n",
    "print(f\"학습 데이터: {len(train_processed_data)}개 예제 처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ac7db-7cc6-4c30-8f83-4b161e10e55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
